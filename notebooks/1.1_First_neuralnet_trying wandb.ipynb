{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/evs/pytorch-ignite-example\" target=\"_blank\">https://app.wandb.ai/evs/pytorch-ignite-example</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/evs/pytorch-ignite-example/runs/csabzg3f\" target=\"_blank\">https://app.wandb.ai/evs/pytorch-ignite-example/runs/csabzg3f</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/evs/pytorch-ignite-example/runs/csabzg3f"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"pytorch-ignite-example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "        \n",
    "from ignite.metrics import Accuracy, Loss\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_features, num_samples):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        \n",
    "        self.latent_features = latent_features\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "        # We encode the data onto the latent space using two linear layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=num_features, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            # A Gaussian is fully characterised by its mean and variance\n",
    "            nn.Linear(in_features=64, out_features=2*self.latent_features) # <- note the 2*latent_features\n",
    "        )\n",
    "        \n",
    "        # The latent code must be decoded into the original image\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=self.latent_features, out_features=64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=64, out_features=128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=128, out_features=256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=256, out_features=num_features)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x): \n",
    "        outputs = {}\n",
    "        \n",
    "        # Split encoder outputs into a mean and variance vector\n",
    "        mu, log_var = torch.chunk(self.encoder(x), 2, dim=-1)\n",
    "        \n",
    "        # :- Reparametrisation trick\n",
    "        # a sample from N(mu, sigma) is mu + sigma * epsilon\n",
    "        # where epsilon ~ N(0, 1)\n",
    "                \n",
    "        # Don't propagate gradients through randomness\n",
    "        with torch.no_grad():\n",
    "            batch_size = mu.size(0)\n",
    "            epsilon = torch.randn(batch_size, self.num_samples, self.latent_features)\n",
    "            \n",
    "            if cuda:\n",
    "                epsilon = epsilon.cuda()\n",
    "        \n",
    "        sigma = torch.exp(log_var/2)\n",
    "        \n",
    "        # We will need to unsqueeze to turn\n",
    "        # (batch_size, latent_dim) -> (batch_size, 1, latent_dim)\n",
    "        z = mu.unsqueeze(1) + epsilon * sigma.unsqueeze(1)        \n",
    "        \n",
    "        # Run through decoder\n",
    "        x = self.decoder(z)\n",
    "        \n",
    "        # The original digits are on the scale [0, 1]\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        # Mean over samples\n",
    "        x_hat = torch.mean(x, dim=1)\n",
    "        \n",
    "        outputs[\"x_hat\"] = x_hat\n",
    "        outputs[\"z\"] = z\n",
    "        outputs[\"mu\"] = mu\n",
    "        outputs[\"log_var\"] = log_var\n",
    "        \n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(train_batch_size, val_batch_size):\n",
    "    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    train_loader = DataLoader(MNIST(download=True, root=\".\", transform=data_transform, train=True),\n",
    "                              batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "    val_loader = DataLoader(MNIST(download=False, root=\".\", transform=data_transform, train=False),\n",
    "                            batch_size=val_batch_size, shuffle=False)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def run(train_batch_size, val_batch_size, epochs, lr, momentum, log_interval):\n",
    "    train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n",
    "    model = Net()\n",
    "    wandb.watch(model)\n",
    "    device = 'cpu'\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "\n",
    "    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    trainer = create_supervised_trainer(model, optimizer, F.nll_loss, device=device)\n",
    "    evaluator = create_supervised_evaluator(model,\n",
    "                                            metrics={'accuracy': Accuracy(),\n",
    "                                                     'nll': Loss(F.nll_loss)},\n",
    "                                            device=device)\n",
    "\n",
    "    desc = \"ITERATION - loss: {:.2f}\"\n",
    "    pbar = tqdm(\n",
    "        initial=0, leave=False, total=len(train_loader),\n",
    "        desc=desc.format(0)\n",
    "    )\n",
    "\n",
    "    @trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n",
    "    def log_training_loss(engine):\n",
    "        pbar.desc = desc.format(engine.state.output)\n",
    "        pbar.update(log_interval)\n",
    "        wandb.log({\"train loss\": engine.state.output})\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(engine):\n",
    "        pbar.refresh()\n",
    "        evaluator.run(train_loader)\n",
    "        metrics = evaluator.state.metrics\n",
    "        avg_accuracy = metrics['accuracy']\n",
    "        avg_nll = metrics['nll']\n",
    "        tqdm.write(\n",
    "            \"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "            .format(engine.state.epoch, avg_accuracy, avg_nll)\n",
    "        )\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation_results(engine):\n",
    "        evaluator.run(val_loader)\n",
    "        metrics = evaluator.state.metrics\n",
    "        avg_accuracy = metrics['accuracy']\n",
    "        avg_nll = metrics['nll']\n",
    "        tqdm.write(\n",
    "            \"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "            .format(engine.state.epoch, avg_accuracy, avg_nll))\n",
    "\n",
    "        pbar.n = pbar.last_print_n = 0\n",
    "        wandb.log({\"validation loss\": avg_nll})\n",
    "        wandb.log({\"validation accuracy\": avg_accuracy})\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=epochs)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/evs/pytorch-ignite-example\" target=\"_blank\">https://app.wandb.ai/evs/pytorch-ignite-example</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/evs/pytorch-ignite-example/runs/7kmmuyqv\" target=\"_blank\">https://app.wandb.ai/evs/pytorch-ignite-example/runs/7kmmuyqv</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ITERATION - loss: 0.00:   0%|          | 0/235 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.32:   4%|▍         | 10/235 [00:00<00:16, 13.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.31:   9%|▊         | 20/235 [00:01<00:16, 13.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.31:  13%|█▎        | 30/235 [00:02<00:16, 12.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.29:  17%|█▋        | 40/235 [00:03<00:15, 12.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.32:  21%|██▏       | 50/235 [00:03<00:14, 13.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.32:  26%|██▌       | 60/235 [00:04<00:12, 13.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.33:  30%|██▉       | 70/235 [00:05<00:12, 13.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.32:  34%|███▍      | 80/235 [00:06<00:13, 11.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.29:  38%|███▊      | 90/235 [00:07<00:12, 11.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.29:  43%|████▎     | 100/235 [00:08<00:12, 11.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.32:  47%|████▋     | 110/235 [00:09<00:11, 10.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.30:  51%|█████     | 120/235 [00:10<00:10, 11.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.31:  55%|█████▌    | 130/235 [00:11<00:09, 11.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.31:  60%|█████▉    | 140/235 [00:11<00:08, 11.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.30:  64%|██████▍   | 150/235 [00:12<00:07, 11.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.30:  68%|██████▊   | 160/235 [00:13<00:06, 12.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.29:  72%|███████▏  | 170/235 [00:14<00:04, 13.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.32:  77%|███████▋  | 180/235 [00:14<00:04, 13.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.29:  81%|████████  | 190/235 [00:15<00:03, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.30:  85%|████████▌ | 200/235 [00:15<00:02, 14.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.30:  89%|████████▉ | 210/235 [00:16<00:01, 14.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.29:  94%|█████████▎| 220/235 [00:17<00:01, 14.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.30:  98%|█████████▊| 230/235 [00:18<00:00, 14.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                       s]\u001b[A\u001b[A\n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [05:23<00:21, 10.77it/s]  \n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [02:32<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.30:  98%|█████████▊| 230/235 [00:29<00:00, 14.57it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 1  Avg accuracy: 0.17 Avg loss: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [05:25<00:21, 10.77it/s]  \n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [02:34<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.30:  98%|█████████▊| 230/235 [00:31<00:00, 14.57it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 1  Avg accuracy: 0.16 Avg loss: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ITERATION - loss: 2.29:   4%|▍         | 10/235 [00:32<01:45,  2.13it/s] \u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.29:   9%|▊         | 20/235 [00:32<01:15,  2.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.28:  13%|█▎        | 30/235 [00:33<00:54,  3.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.26:  17%|█▋        | 40/235 [00:34<00:40,  4.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.28:  21%|██▏       | 50/235 [00:34<00:30,  5.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.28:  26%|██▌       | 60/235 [00:35<00:24,  7.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.29:  30%|██▉       | 70/235 [00:36<00:19,  8.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.27:  34%|███▍      | 80/235 [00:37<00:16,  9.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.30:  38%|███▊      | 90/235 [00:37<00:13, 10.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.27:  43%|████▎     | 100/235 [00:38<00:11, 11.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.27:  47%|████▋     | 110/235 [00:39<00:10, 12.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.29:  51%|█████     | 120/235 [00:39<00:09, 12.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.28:  55%|█████▌    | 130/235 [00:40<00:07, 13.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.27:  60%|█████▉    | 140/235 [00:41<00:07, 13.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.27:  64%|██████▍   | 150/235 [00:42<00:06, 13.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.28:  68%|██████▊   | 160/235 [00:42<00:05, 13.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.28:  72%|███████▏  | 170/235 [00:43<00:04, 13.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.27:  77%|███████▋  | 180/235 [00:44<00:04, 13.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.28:  81%|████████  | 190/235 [00:45<00:03, 13.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.23:  85%|████████▌ | 200/235 [00:45<00:02, 14.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.25:  89%|████████▉ | 210/235 [00:46<00:01, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.26:  94%|█████████▎| 220/235 [00:47<00:01, 14.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.25:  98%|█████████▊| 230/235 [00:47<00:00, 14.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.25: 240it [00:48, 14.86it/s]                         \u001b[A\u001b[A\n",
      "\n",
      "                                                                       \n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [05:52<00:21, 10.77it/s]\n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [03:00<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.25: 240it [00:58, 14.86it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 2  Avg accuracy: 0.28 Avg loss: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [05:54<00:21, 10.77it/s]\n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [03:02<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.25: 240it [00:59, 14.86it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 2  Avg accuracy: 0.27 Avg loss: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ITERATION - loss: 2.26:   4%|▍         | 10/235 [01:00<01:33,  2.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.26:   9%|▊         | 20/235 [01:01<01:07,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.25:  13%|█▎        | 30/235 [01:02<00:49,  4.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.26:  17%|█▋        | 40/235 [01:02<00:36,  5.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.25:  21%|██▏       | 50/235 [01:03<00:28,  6.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.23:  26%|██▌       | 60/235 [01:04<00:22,  7.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.24:  30%|██▉       | 70/235 [01:04<00:18,  8.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.22:  34%|███▍      | 80/235 [01:05<00:15, 10.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.25:  38%|███▊      | 90/235 [01:06<00:12, 11.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.21:  43%|████▎     | 100/235 [01:06<00:10, 12.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.22:  47%|████▋     | 110/235 [01:07<00:09, 13.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.23:  51%|█████     | 120/235 [01:08<00:08, 13.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.23:  55%|█████▌    | 130/235 [01:08<00:07, 13.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.23:  60%|█████▉    | 140/235 [01:09<00:06, 14.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.23:  64%|██████▍   | 150/235 [01:10<00:05, 14.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.23:  68%|██████▊   | 160/235 [01:10<00:05, 14.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.21:  72%|███████▏  | 170/235 [01:11<00:04, 15.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.23:  77%|███████▋  | 180/235 [01:12<00:03, 15.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.21:  81%|████████  | 190/235 [01:12<00:03, 14.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.22:  85%|████████▌ | 200/235 [01:13<00:02, 15.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.22:  89%|████████▉ | 210/235 [01:14<00:01, 15.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.21:  94%|█████████▎| 220/235 [01:14<00:00, 15.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.22:  98%|█████████▊| 230/235 [01:15<00:00, 15.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                       s]\u001b[A\u001b[A\n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [06:19<00:21, 10.77it/s]  \n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [03:27<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.22:  98%|█████████▊| 230/235 [01:24<00:00, 15.52it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 3  Avg accuracy: 0.40 Avg loss: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                                                                       s]\u001b[A\u001b[A\n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [06:20<00:21, 10.77it/s]  \n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [03:29<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.22:  98%|█████████▊| 230/235 [01:26<00:00, 15.52it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 3  Avg accuracy: 0.40 Avg loss: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ITERATION - loss: 2.21:   4%|▍         | 10/235 [01:27<01:28,  2.54it/s] \u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.22:   9%|▊         | 20/235 [01:27<01:03,  3.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.21:  13%|█▎        | 30/235 [01:28<00:46,  4.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.20:  17%|█▋        | 40/235 [01:28<00:34,  5.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.20:  21%|██▏       | 50/235 [01:29<00:26,  6.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.16:  26%|██▌       | 60/235 [01:30<00:21,  8.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.22:  30%|██▉       | 70/235 [01:30<00:16,  9.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.21:  34%|███▍      | 80/235 [01:31<00:14, 10.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.19:  38%|███▊      | 90/235 [01:32<00:12, 11.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.18:  43%|████▎     | 100/235 [01:32<00:10, 12.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.20:  47%|████▋     | 110/235 [01:33<00:09, 13.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.20:  51%|█████     | 120/235 [01:34<00:08, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.18:  55%|█████▌    | 130/235 [01:34<00:07, 14.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.18:  60%|█████▉    | 140/235 [01:35<00:06, 14.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.15:  64%|██████▍   | 150/235 [01:36<00:05, 15.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.19:  68%|██████▊   | 160/235 [01:36<00:04, 15.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.20:  72%|███████▏  | 170/235 [01:37<00:04, 15.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.14:  77%|███████▋  | 180/235 [01:38<00:03, 15.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.15:  81%|████████  | 190/235 [01:38<00:02, 15.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.14:  85%|████████▌ | 200/235 [01:39<00:02, 15.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.16:  89%|████████▉ | 210/235 [01:39<00:01, 15.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.16:  94%|█████████▎| 220/235 [01:40<00:00, 15.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.15:  98%|█████████▊| 230/235 [01:41<00:00, 15.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.13: 240it [01:41, 15.67it/s]                         \u001b[A\u001b[A\n",
      "\n",
      "                                                                       \n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [06:45<00:21, 10.77it/s]\n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [03:53<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.13: 240it [01:51, 15.67it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 4  Avg accuracy: 0.52 Avg loss: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [06:47<00:21, 10.77it/s]\n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [03:55<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.13: 240it [01:52, 15.67it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 4  Avg accuracy: 0.52 Avg loss: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ITERATION - loss: 2.11:   4%|▍         | 10/235 [01:53<01:28,  2.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.13:   9%|▊         | 20/235 [01:54<01:03,  3.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.15:  13%|█▎        | 30/235 [01:54<00:46,  4.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.11:  17%|█▋        | 40/235 [01:55<00:34,  5.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.12:  21%|██▏       | 50/235 [01:56<00:26,  6.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.10:  26%|██▌       | 60/235 [01:56<00:20,  8.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.11:  30%|██▉       | 70/235 [01:57<00:16,  9.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.10:  34%|███▍      | 80/235 [01:58<00:14, 10.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.10:  38%|███▊      | 90/235 [01:58<00:12, 11.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.06:  43%|████▎     | 100/235 [01:59<00:10, 12.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.10:  47%|████▋     | 110/235 [01:59<00:09, 13.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.08:  51%|█████     | 120/235 [02:00<00:08, 14.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.07:  55%|█████▌    | 130/235 [02:01<00:07, 14.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.08:  60%|█████▉    | 140/235 [02:01<00:06, 14.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.07:  64%|██████▍   | 150/235 [02:02<00:05, 15.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.04:  68%|██████▊   | 160/235 [02:03<00:05, 14.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.00:  72%|███████▏  | 170/235 [02:03<00:04, 14.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.08:  77%|███████▋  | 180/235 [02:04<00:03, 14.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.04:  81%|████████  | 190/235 [02:05<00:02, 15.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.03:  85%|████████▌ | 200/235 [02:05<00:02, 15.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.01:  89%|████████▉ | 210/235 [02:06<00:01, 15.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.03:  94%|█████████▎| 220/235 [02:07<00:00, 15.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.03:  98%|█████████▊| 230/235 [02:07<00:00, 15.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                       s]\u001b[A\u001b[A\n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [07:11<00:21, 10.77it/s]  \n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [04:19<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.03:  98%|█████████▊| 230/235 [02:17<00:00, 15.56it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 5  Avg accuracy: 0.60 Avg loss: 1.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [07:13<00:21, 10.77it/s]  \n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [04:21<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.03:  98%|█████████▊| 230/235 [02:18<00:00, 15.56it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 5  Avg accuracy: 0.61 Avg loss: 1.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ITERATION - loss: 1.99:   4%|▍         | 10/235 [02:19<01:28,  2.55it/s] \u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 2.03:   9%|▊         | 20/235 [02:19<01:03,  3.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.99:  13%|█▎        | 30/235 [02:20<00:46,  4.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.99:  17%|█▋        | 40/235 [02:21<00:34,  5.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.94:  21%|██▏       | 50/235 [02:21<00:26,  6.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.98:  26%|██▌       | 60/235 [02:22<00:20,  8.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.91:  30%|██▉       | 70/235 [02:23<00:16,  9.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.96:  34%|███▍      | 80/235 [02:23<00:14, 10.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.96:  38%|███▊      | 90/235 [02:24<00:12, 12.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.91:  43%|████▎     | 100/235 [02:25<00:10, 12.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.94:  47%|████▋     | 110/235 [02:25<00:09, 13.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.94:  51%|█████     | 120/235 [02:26<00:08, 14.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.93:  55%|█████▌    | 130/235 [02:27<00:07, 14.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.99:  60%|█████▉    | 140/235 [02:27<00:06, 14.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.94:  64%|██████▍   | 150/235 [02:28<00:05, 14.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.94:  68%|██████▊   | 160/235 [02:29<00:05, 14.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.92:  72%|███████▏  | 170/235 [02:29<00:04, 15.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.84:  77%|███████▋  | 180/235 [02:30<00:03, 15.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.87:  81%|████████  | 190/235 [02:30<00:02, 15.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.82:  85%|████████▌ | 200/235 [02:31<00:02, 15.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.87:  89%|████████▉ | 210/235 [02:32<00:01, 15.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.84:  94%|█████████▎| 220/235 [02:32<00:00, 15.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.82:  98%|█████████▊| 230/235 [02:33<00:00, 15.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.77: 240it [02:34, 15.75it/s]                         \u001b[A\u001b[A\n",
      "\n",
      "                                                                       \n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [07:37<00:21, 10.77it/s]\n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [04:46<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.77: 240it [02:43, 15.75it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 6  Avg accuracy: 0.67 Avg loss: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [07:39<00:21, 10.77it/s]\n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [04:47<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.77: 240it [02:45, 15.75it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 6  Avg accuracy: 0.68 Avg loss: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ITERATION - loss: 1.77:   0%|          | 0/235 [02:45<00:14, 15.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.75:   4%|▍         | 10/235 [02:45<01:28,  2.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.84:   9%|▊         | 20/235 [02:46<01:03,  3.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.77:  13%|█▎        | 30/235 [02:47<00:46,  4.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.84:  17%|█▋        | 40/235 [02:47<00:34,  5.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.76:  21%|██▏       | 50/235 [02:48<00:26,  6.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.74:  26%|██▌       | 60/235 [02:48<00:20,  8.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.81:  30%|██▉       | 70/235 [02:49<00:16,  9.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.81:  34%|███▍      | 80/235 [02:50<00:14, 10.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.74:  38%|███▊      | 90/235 [02:50<00:12, 11.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.85:  43%|████▎     | 100/235 [02:51<00:10, 12.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.73:  47%|████▋     | 110/235 [02:52<00:09, 13.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.73:  51%|█████     | 120/235 [02:52<00:08, 14.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.71:  55%|█████▌    | 130/235 [02:53<00:07, 14.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.63:  60%|█████▉    | 140/235 [02:54<00:06, 14.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.78:  64%|██████▍   | 150/235 [02:54<00:05, 14.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.62:  68%|██████▊   | 160/235 [02:55<00:04, 15.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.63:  72%|███████▏  | 170/235 [02:56<00:04, 15.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.61:  77%|███████▋  | 180/235 [02:56<00:03, 15.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.68:  81%|████████  | 190/235 [02:57<00:03, 14.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.64:  85%|████████▌ | 200/235 [02:58<00:02, 14.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.59:  89%|████████▉ | 210/235 [02:58<00:01, 15.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.66:  94%|█████████▎| 220/235 [02:59<00:00, 15.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.75:  98%|█████████▊| 230/235 [03:00<00:00, 15.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                       s]\u001b[A\u001b[A\n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [08:04<00:21, 10.77it/s]  \n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [05:12<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.75:  98%|█████████▊| 230/235 [03:09<00:00, 15.46it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 7  Avg accuracy: 0.72 Avg loss: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [08:05<00:21, 10.77it/s]  \n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [05:13<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.75:  98%|█████████▊| 230/235 [03:11<00:00, 15.46it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 7  Avg accuracy: 0.73 Avg loss: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ITERATION - loss: 1.62:   4%|▍         | 10/235 [03:11<01:29,  2.52it/s] \u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.69:   9%|▊         | 20/235 [03:12<01:03,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.60:  13%|█▎        | 30/235 [03:13<00:46,  4.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.64:  17%|█▋        | 40/235 [03:13<00:34,  5.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.60:  21%|██▏       | 50/235 [03:14<00:26,  6.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.55:  26%|██▌       | 60/235 [03:14<00:21,  8.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.51:  30%|██▉       | 70/235 [03:15<00:17,  9.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.60:  34%|███▍      | 80/235 [03:16<00:14, 10.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.60:  38%|███▊      | 90/235 [03:16<00:12, 11.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.65:  43%|████▎     | 100/235 [03:17<00:10, 12.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.59:  47%|████▋     | 110/235 [03:18<00:09, 13.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.52:  51%|█████     | 120/235 [03:18<00:08, 14.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.53:  55%|█████▌    | 130/235 [03:19<00:07, 14.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.70:  60%|█████▉    | 140/235 [03:20<00:06, 14.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.46:  64%|██████▍   | 150/235 [03:20<00:05, 14.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.54:  68%|██████▊   | 160/235 [03:21<00:05, 14.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.51:  72%|███████▏  | 170/235 [03:22<00:04, 15.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.48:  77%|███████▋  | 180/235 [03:22<00:03, 15.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.42:  81%|████████  | 190/235 [03:23<00:02, 15.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.44:  85%|████████▌ | 200/235 [03:24<00:02, 15.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.54:  89%|████████▉ | 210/235 [03:24<00:01, 15.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.49:  94%|█████████▎| 220/235 [03:25<00:00, 15.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.44:  98%|█████████▊| 230/235 [03:26<00:00, 15.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.64: 240it [03:26, 15.39it/s]                         \u001b[A\u001b[A\n",
      "\n",
      "                                                                       \n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [08:30<00:21, 10.77it/s]\n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [05:38<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.64: 240it [03:36, 15.39it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 8  Avg accuracy: 0.76 Avg loss: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [08:32<00:21, 10.77it/s]\n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [05:40<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.64: 240it [03:37, 15.39it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 8  Avg accuracy: 0.77 Avg loss: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ITERATION - loss: 1.43:   4%|▍         | 10/235 [03:38<01:29,  2.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.42:   9%|▊         | 20/235 [03:39<01:04,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.41:  13%|█▎        | 30/235 [03:39<00:46,  4.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.48:  17%|█▋        | 40/235 [03:40<00:35,  5.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.44:  21%|██▏       | 50/235 [03:41<00:27,  6.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.38:  26%|██▌       | 60/235 [03:41<00:21,  8.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.46:  30%|██▉       | 70/235 [03:42<00:17,  9.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.38:  34%|███▍      | 80/235 [03:43<00:14, 10.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.36:  38%|███▊      | 90/235 [03:43<00:12, 11.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.40:  43%|████▎     | 100/235 [03:44<00:10, 12.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.37:  47%|████▋     | 110/235 [03:45<00:09, 13.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.25:  51%|█████     | 120/235 [03:45<00:08, 13.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.35:  55%|█████▌    | 130/235 [03:46<00:07, 14.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.37:  60%|█████▉    | 140/235 [03:47<00:06, 14.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.36:  64%|██████▍   | 150/235 [03:47<00:05, 15.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.34:  68%|██████▊   | 160/235 [03:48<00:04, 15.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.31:  72%|███████▏  | 170/235 [03:48<00:04, 15.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.38:  77%|███████▋  | 180/235 [03:49<00:03, 15.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.28:  81%|████████  | 190/235 [03:50<00:02, 15.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.39:  85%|████████▌ | 200/235 [03:50<00:02, 15.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.39:  89%|████████▉ | 210/235 [03:51<00:01, 15.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.29:  94%|█████████▎| 220/235 [03:52<00:00, 15.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.23:  98%|█████████▊| 230/235 [03:52<00:00, 15.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                                       s]\u001b[A\u001b[A\n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [08:56<00:21, 10.77it/s]  \n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [06:05<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.23:  98%|█████████▊| 230/235 [04:02<00:00, 15.29it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 9  Avg accuracy: 0.79 Avg loss: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [08:58<00:21, 10.77it/s]  \n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [06:06<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.23:  98%|█████████▊| 230/235 [04:04<00:00, 15.29it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 9  Avg accuracy: 0.80 Avg loss: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ITERATION - loss: 1.34:   4%|▍         | 10/235 [04:04<01:29,  2.52it/s] \u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.32:   9%|▊         | 20/235 [04:05<01:03,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.31:  13%|█▎        | 30/235 [04:05<00:46,  4.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.35:  17%|█▋        | 40/235 [04:06<00:34,  5.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.31:  21%|██▏       | 50/235 [04:07<00:26,  6.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.17:  26%|██▌       | 60/235 [04:07<00:20,  8.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.25:  30%|██▉       | 70/235 [04:08<00:16,  9.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.30:  34%|███▍      | 80/235 [04:09<00:14, 10.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.20:  38%|███▊      | 90/235 [04:09<00:11, 12.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.20:  43%|████▎     | 100/235 [04:10<00:10, 12.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.23:  47%|████▋     | 110/235 [04:10<00:09, 13.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.18:  51%|█████     | 120/235 [04:11<00:08, 14.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.27:  55%|█████▌    | 130/235 [04:12<00:07, 14.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.24:  60%|█████▉    | 140/235 [04:12<00:06, 14.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.23:  64%|██████▍   | 150/235 [04:13<00:05, 15.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.32:  68%|██████▊   | 160/235 [04:14<00:04, 15.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.31:  72%|███████▏  | 170/235 [04:14<00:04, 15.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.16:  77%|███████▋  | 180/235 [04:15<00:03, 15.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.30:  81%|████████  | 190/235 [04:16<00:02, 15.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.17:  85%|████████▌ | 200/235 [04:16<00:02, 15.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.23:  89%|████████▉ | 210/235 [04:17<00:01, 15.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.14:  94%|█████████▎| 220/235 [04:18<00:00, 15.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.14:  98%|█████████▊| 230/235 [04:18<00:00, 15.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.11: 240it [04:19, 15.74it/s]                         \u001b[A\u001b[A\n",
      "\n",
      "                                                                       \n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [09:22<00:21, 10.77it/s]\n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [06:31<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.11: 240it [04:28, 15.74it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 10  Avg accuracy: 0.81 Avg loss: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \n",
      "\u001b[A                                                                    \n",
      "\n",
      "ITERATION - loss: 2.29:   0%|          | 0/235 [09:24<00:21, 10.77it/s]\n",
      "ITERATION - loss: 2.30:   0%|          | 0/235 [06:32<00:15, 15.30it/s]\u001b[A\n",
      "\n",
      "ITERATION - loss: 1.11: 240it [04:30, 15.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "                                                \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 10  Avg accuracy: 0.82 Avg loss: 0.79\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "\n",
    "hyperparameter_defaults = dict(\n",
    "    batch_size = 256,\n",
    "    val_batch_size = 100,\n",
    "    epochs = 10,\n",
    "    lr = 0.001,\n",
    "    momentum = 0.3,\n",
    "    log_interval = 10,\n",
    ")\n",
    "\n",
    "\n",
    "# Get metrics in Weights & Biases\n",
    "wandb.init(config=hyperparameter_defaults, project=\"pytorch-ignite-example\")\n",
    "config = wandb.config\n",
    "run(config.batch_size, config.val_batch_size, config.epochs, config.lr, config.momentum, config.log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
