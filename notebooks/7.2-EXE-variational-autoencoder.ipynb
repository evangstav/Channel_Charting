{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/evs/Vae-test-2\" target=\"_blank\">https://app.wandb.ai/evs/Vae-test-2</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/evs/Vae-test-2/runs/6w6ugzqn\" target=\"_blank\">https://app.wandb.ai/evs/Vae-test-2/runs/6w6ugzqn</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/evs/Vae-test-2/runs/6w6ugzqn"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project='Vae-test-2', allow_val_change=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display, clear_output\n",
    "import numpy as np\n",
    "%matplotlib nbagg\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(sns.dark_palette(\"purple\"))\n",
    "from sklearn.decomposition import PCA\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = Normalize(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "from functools import reduce\n",
    "\n",
    "# Flatten the images into a vector\n",
    "flatten = lambda x: ToTensor()(x).view(28**2)\n",
    "transform = Compose([\n",
    "                  #   norm, \n",
    "                     flatten\n",
    "                    ])\n",
    "\n",
    "# Define the train and test sets\n",
    "dset_train = MNIST(\"./\", train=True,  transform=transform, download=True)\n",
    "dset_test  = MNIST(\"./\", train=False, transform=transform)\n",
    "\n",
    "# The digit classes to use\n",
    "classes = [3, 5, 6, 9]\n",
    "\n",
    "def stratified_sampler(labels):\n",
    "    \"\"\"Sampler that only picks datapoints corresponding to the specified classes\"\"\"\n",
    "    (indices,) = np.where(reduce(lambda x, y: x | y, [labels.numpy() == i for i in classes]))\n",
    "    indices = torch.from_numpy(indices)\n",
    "    return SubsetRandomSampler(indices)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model\n",
    "When defining the model the latent layer must act as a bottleneck of information, so that we ensure that we find a strong internal representation. We initialize the VAE with 1 hidden layer in the encoder and decoder using relu units as non-linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.functional import softplus\n",
    "\n",
    "# define size variables\n",
    "num_features = 28**2\n",
    "\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_features, num_samples):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        \n",
    "        self.latent_features = latent_features\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "        # We encode the data onto the latent space using two linear layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=num_features, out_features=128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.BatchNorm1d(64),\n",
    "\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # A Gaussian is fully characterised by its mean and variance\n",
    "            nn.Linear(in_features=32, out_features=2*self.latent_features), # <- note the 2*latent_features\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        # The latent code must be decoded into the original image\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=self.latent_features, out_features=32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=32, out_features=64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=64, out_features=128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=128, out_features=num_features)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x): \n",
    "        outputs = {}\n",
    "        \n",
    "        # Split encoder outputs into a mean and variance vector\n",
    "        mu, log_var = torch.chunk(self.encoder(x), 2, dim=-1)\n",
    "        \n",
    "        # :- Reparametrisation trick\n",
    "        # a sample from N(mu, sigma) is mu + sigma * epsilon\n",
    "        # where epsilon ~ N(0, 1)\n",
    "                \n",
    "        # Don't propagate gradients through randomness\n",
    "        with torch.no_grad():\n",
    "            batch_size = mu.size(0)\n",
    "            epsilon = torch.randn(batch_size, self.num_samples, self.latent_features)\n",
    "            \n",
    "            if cuda:\n",
    "                epsilon = epsilon.cuda()\n",
    "        \n",
    "        sigma = torch.exp(log_var/2)\n",
    "        \n",
    "        # We will need to unsqueeze to turn\n",
    "        # (batch_size, latent_dim) -> (batch_size, 1, latent_dim)\n",
    "        z = mu.unsqueeze(1) + epsilon * sigma.unsqueeze(1)        \n",
    "        \n",
    "        # Run through decoder\n",
    "        x = self.decoder(z)\n",
    "        \n",
    "        # The original digits are on the scale [0, 1]\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        # Mean over samples\n",
    "        x_hat = torch.mean(x, dim=1)\n",
    "        \n",
    "        outputs[\"x_hat\"] = x_hat\n",
    "        outputs[\"z\"] = z\n",
    "        outputs[\"mu\"] = mu\n",
    "        outputs[\"log_var\"] = log_var\n",
    "        \n",
    "        return outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following we define the PyTorch functions for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import binary_cross_entropy\n",
    "from torch import optim\n",
    "\n",
    "def ELBO_loss(y, t, mu, log_var):\n",
    "    # Reconstruction error, log[p(x|z)]\n",
    "    # Sum over features\n",
    "    likelihood = -binary_cross_entropy(y, t, reduction=\"none\")\n",
    "    likelihood = likelihood.view(likelihood.size(0), -1).sum(1)\n",
    "\n",
    "    # Regularization error: \n",
    "    # Kulback-Leibler divergence between approximate posterior, q(z|x)\n",
    "    # and prior p(z) = N(z | mu, sigma*I).\n",
    "    \n",
    "    # In the case of the KL-divergence between diagonal covariance Gaussian and \n",
    "    # a standard Gaussian, an analytic solution exists. Using this excerts a lower\n",
    "    # variance estimator of KL(q||p)\n",
    "    kl = -0.5 * torch.sum(1 + log_var - mu**2 - torch.exp(log_var), dim=1)\n",
    "\n",
    "    # Combining the two terms in the evidence lower bound objective (ELBO) \n",
    "    # mean over batch\n",
    "    ELBO = torch.mean(likelihood) - torch.mean(kl)\n",
    "    \n",
    "    # notice minus sign as we want to maximise ELBO\n",
    "    return -ELBO, kl.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the forward pass, to check that everything is in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the training loop we sample each batch and evaluate the error, latent space, and reconstructions on every epoch.\n",
    "\n",
    "**NOTE** this will take a while on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    # Switch model to training mode. This is necessary for layers like dropout, batchnorm etc which behave differently in training and evaluation mode\n",
    "    model.train()\n",
    "    \n",
    "    # We loop over the data iterator, and feed the inputs to the network and adjust the weights.\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if batch_idx > 20:\n",
    "          break\n",
    "        # Load the input features and labels from the training dataset\n",
    "        x, y = data.to(device), target.to(device)\n",
    "\n",
    "        # Reset the gradients to 0 for all learnable weight parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: Pass image data from training dataset, make predictions about class image belongs to (0-9 in this case)\n",
    "        outputs = model(x)\n",
    "        \n",
    "        # Define our loss function, and compute the loss\n",
    "        x_hat = outputs['x_hat']\n",
    "        mu, log_var = outputs['mu'], outputs['log_var']\n",
    "        #print(x_hat.shape, x.shape, mu.shape, log_var.shape)\n",
    "\n",
    "        elbo, kl = loss_function(x_hat, x, mu, log_var)        \n",
    "        # Backward pass: compute the gradients of the loss w.r.t. the model's parameters\n",
    "        elbo.backward()\n",
    "        \n",
    "        # Update the neural network weights\n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(),5)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        wandb.log({\n",
    "        \"Train elbo\": elbo.item(),\n",
    "        \"Train KL\": kl.item()\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader, classes):\n",
    "    # Switch model to evaluation mode. This is necessary for layers like dropout, batchnorm etc which behave differently in training and evaluation mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    example_images = []\n",
    "    with torch.no_grad():\n",
    "        data, target = next(iter(test_loader))\n",
    "        # Load the input features and labels from the test dataset\n",
    "        x, y = data.to(device), target.to(device)\n",
    "\n",
    "        # Make predictions: Pass image data from test dataset, make predictions about class image belongs to (0-9 in this case)\n",
    "        outputs = model(x)\n",
    "\n",
    "        # Compute the loss sum up batch loss\n",
    "        x_hat = outputs['x_hat']\n",
    "        mu, log_var = outputs['mu'], outputs['log_var']\n",
    "        z = outputs[\"z\"]\n",
    "\n",
    "        elbo, kl = loss_function(x_hat, x, mu, log_var)\n",
    "\n",
    "        # We save the latent variable and reconstruction for later use\n",
    "        # we will need them on the CPU to plot\n",
    "        x = x.to(\"cpu\")\n",
    "        x_hat = x_hat.to(\"cpu\")\n",
    "        z = z.detach().to(\"cpu\").numpy()\n",
    "        \n",
    "        #visualize latent space\n",
    "        rows = 8\n",
    "        columns = args.batch_size // rows\n",
    "        plt.title('Latent space')\n",
    "        plt.xlabel('Dimension 1')\n",
    "        plt.ylabel('Dimension 2')\n",
    "\n",
    "        span = np.linspace(-4, 4, rows)\n",
    "        grid = np.dstack(np.meshgrid(span, span)).reshape(-1, 2)\n",
    "\n",
    "        # If you want to use a dimensionality reduction method you can use\n",
    "        # for example PCA by projecting on two principal dimensions\n",
    "        z = PCA(n_components=2).fit_transform(np.mean(z, axis=1))\n",
    "\n",
    "        colors = iter(plt.get_cmap('Set1')(np.linspace(0, 1.0, len(classes))))\n",
    "        for c in classes:\n",
    "            plt.scatter(*z[c == y.numpy()].reshape(-1, 2).T, c=next(colors), marker='o', label=c)\n",
    "        \n",
    "        show_sampling_points=True\n",
    "        if show_sampling_points:\n",
    "            plt.scatter(*grid.T, color=\"k\", marker=\"x\", alpha=0.5, label=\"Sampling points\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # WandB – wandb.log(a_dict) logs the keys and values of the dictionary passed in and associates the values with a step.\n",
    "    # You can log anything by passing it to wandb.log, including histograms, custom matplotlib objects, images, video, text, tables, html, pointclouds and other 3D objects.\n",
    "    # Here we use it to log test accuracy, loss and some test images (along with their true and predicted labels).\n",
    "    wandb.log({\n",
    "        \"Latent Space\": plt,\n",
    "        \"Test elbo\": elbo.item(),\n",
    "        \"Test KL\": kl.item()\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
    "config = wandb.config          # Initialize config\n",
    "config.batch_size = 32         # input batch size for training (default: 64)\n",
    "config.test_batch_size = 10    # input batch size for testing (default: 1000)\n",
    "config.epochs = 100             # number of epochs to train (default: 10)\n",
    "config.lr = 0.1               # learning rate (default: 0.01)\n",
    "config.momentum = 0.5          # SGD momentum (default: 0.5) \n",
    "config.no_cuda = False         # disables CUDA training\n",
    "config.seed = 42               # random seed (default: 42)\n",
    "config.log_interval = 10     # how many batches to wait before logging training status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = not config.no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "# Set random seeds and deterministic pytorch for reproducibility\n",
    "# random.seed(config.seed)       # python random seed\n",
    "torch.manual_seed(config.seed) # pytorch random seed\n",
    "# numpy.random.seed(config.seed) # numpy random seed\n",
    "torch.backends.cudnn.deterministic = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7f79a1757850>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "latent_features = 4\n",
    "num_samples = 2\n",
    "\n",
    "# Initialize our model, recursively go over all modules and convert their parameters and buffers to CUDA tensors (if device is set to cuda)\n",
    "model = VariationalAutoencoder(latent_features, num_samples).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "loss_function = ELBO_loss\n",
    "wandb.watch(model, log=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loaders perform the actual work\n",
    "train_loader = DataLoader(dset_train, batch_size=config.batch_size,\n",
    "                          sampler=stratified_sampler(dset_train.train_labels), pin_memory=False)\n",
    "test_loader  = DataLoader(dset_test, batch_size=config.batch_size, \n",
    "                          sampler=stratified_sampler(dset_test.targets), pin_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ToTensor() takes no arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-b9fe01fd5682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/channel-charting-8NuP_Ebk-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/channel-charting-8NuP_Ebk-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/channel-charting-8NuP_Ebk-py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/channel-charting-8NuP_Ebk-py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/channel-charting-8NuP_Ebk-py3.8/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/channel-charting-8NuP_Ebk-py3.8/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ToTensor() takes no arguments"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "x, _ = next(iter(train_loader))\n",
    "x = Variable(x)\n",
    "\n",
    "cuda=False\n",
    "\n",
    "outputs = model(x)\n",
    "\n",
    "x_hat = outputs[\"x_hat\"]\n",
    "mu, log_var = outputs[\"mu\"], outputs[\"log_var\"]\n",
    "z = outputs[\"z\"]\n",
    "\n",
    "loss, kl = loss_function(x_hat, x, mu, log_var)\n",
    "\n",
    "print(x.shape)\n",
    "print(x_hat.shape)\n",
    "print(z.shape)\n",
    "print(loss)\n",
    "print(kl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm.tqdm(range(1, config.epochs + 1)):\n",
    "    train(config, model, device, train_loader, optimizer, epoch)\n",
    "    test(config, model, device, test_loader, classes)\n",
    "\n",
    "# WandB – Save the model checkpoint. This automatically saves a file to the cloud and associates it with the current run.\n",
    "torch.save(model.state_dict(), \"model.h5\")\n",
    "\n",
    "wandb.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input=torch.randn(10, latent_features)\n",
    "plt.imshow(model.decoder(random_input).detach().numpy().reshape(10,28,28)[0], cmap=\"binary_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in test_loader:\n",
    "    x = x\n",
    "    y = y\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(model(x)['x_hat'].detach().numpy()[1].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[1].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = torch.randn(1000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = model(random)['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "rndperm = np.random.permutation(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(latent[:,0,:].detach())\n",
    "\n",
    "df['pca-one'] = pca_result[:,0]\n",
    "df['pca-two'] = pca_result[:,1] \n",
    "df['pca-three'] = pca_result[:,2]\n",
    "\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=df[\"pca-two\"], \n",
    "    y=df[\"pca-three\"],\n",
    "    #hue=df[\"pca-three\"],\n",
    "    palette=sns.color_palette(\"hls\", len(df)),\n",
    "    data=df.loc[rndperm,:],\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = [model.encoder(x).detach().numpy() for x,_  in test_loader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [y for _,y in test_loader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.cat(labels, axis=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = np.concatenate(encodings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "X_tsne = tsne.fit_transform(encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(X_tsne[:100,0], X_tsne[:100,1], hue=labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=X_tsne, columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(df.x, df.y, hue=df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2).fit_transform(encodings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=pca, columns=['x', 'y'])\n",
    "df['label'] = labels\n",
    "sns.scatterplot(df.x, df.y, hue=df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    sns.distplot(encodings[:,i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
