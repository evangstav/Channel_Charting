{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.fft as fft\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/evangelos/workspace/Channel_Charting/\")\n",
    "from tools import utils\n",
    "from src.models import supervised_classifier, supervised_regressor\n",
    "from src.utils.data_preparation import SupervisedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "(raw_taps, raw_phi, raw_theta, raw_rx_positions, raw_tx_positions) = utils.load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fourier transform and undersample taps\n",
    "raw_freq_taps = fft.fft(raw_taps , workers=-1)[:,:,::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_freq = np.mean(raw_freq_taps, axis=(1,2))\n",
    "mu = np.mean(mean_freq)\n",
    "std = np.std(mean_freq)\n",
    "idcs = ~(np.abs(mean_freq-mu) >3*std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data, first_data, rx_positions=None, padding=True, reduce=False, keep_idces=idcs):\n",
    "    data = data[idcs]\n",
    "    if rx_positions:\n",
    "        data = utils.drop_top_right(data, rx_positions)\n",
    "    data = utils.standarize(data)\n",
    "    data = utils.fillna(data)\n",
    "    if padding:\n",
    "        data = utils.zero_padding_as(data, first_data)\n",
    "    #data = utils.take_norm(data)\n",
    "    if reduce:\n",
    "        data = reduce_to_mean_std(data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def reduce_to_mean_std(x):\n",
    "    return np.stack([np.mean(x,axis=1), \n",
    "                          np.std(x,axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "taps = preprocessing(raw_freq_taps, raw_freq_taps)\n",
    "taps = np.hstack([np.real(taps), np.imag(taps)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = preprocessing(raw_phi, taps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = preprocessing(raw_theta, taps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = preprocessing(raw_rx_positions, taps, padding=False, reduce=False)[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([taps, phi[:-10], theta[:-10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign labels to certain areas of the map using kmeans\n",
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters=8) \n",
    "km = km.fit(y)\n",
    "labels = km.predict(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y[:,0], y[:,1], hue=labels, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "train_X, test_X ,train_y, test_y, train_labels, test_labels = train_test_split(X, y, labels, train_size=0.1, test_size=0.1)\n",
    "train_DS = SupervisedDataset(train_X, train_labels)\n",
    "test_DS = SupervisedDataset(test_X, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_DS, batch_size=32)\n",
    "test_loader = DataLoader(test_DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "model = supervised_classifier.Classifier(channels=train_DS.channels(), nb_labels=8)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a314dc157cb46749bb79ca2ea9bff71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss 0.06475594766516435, Validation Loss 1.9161578823721368, Validation Accuracy 0.24537037037037038\n",
      "Epoch 2: Training Loss 0.056171975838510614, Validation Loss 1.6578630699606782, Validation Accuracy 0.3413299663299663\n",
      "Epoch 3: Training Loss 0.04940608667072497, Validation Loss 1.5400295177034042, Validation Accuracy 0.3985690235690236\n",
      "Epoch 4: Training Loss 0.04634516999596044, Validation Loss 1.451141759601461, Validation Accuracy 0.43392255892255893\n",
      "Epoch 5: Training Loss 0.04455153256968448, Validation Loss 1.4191720065586693, Validation Accuracy 0.4532828282828283\n",
      "Epoch 6: Training Loss 0.04326697773682444, Validation Loss 1.368351403358504, Validation Accuracy 0.49074074074074076\n",
      "Epoch 7: Training Loss 0.04142431547767238, Validation Loss 1.335725130479711, Validation Accuracy 0.5058922558922558\n",
      "Epoch 8: Training Loss 0.041026750464188425, Validation Loss 1.3363925233198009, Validation Accuracy 0.5046296296296297\n",
      "Epoch 9: Training Loss 0.04010982116899992, Validation Loss 1.314872281977881, Validation Accuracy 0.507996632996633\n",
      "Epoch 10: Training Loss 0.03809622664200632, Validation Loss 1.2785304276609162, Validation Accuracy 0.5332491582491582\n",
      "Epoch 11: Training Loss 0.03782052765394512, Validation Loss 1.2800066145093467, Validation Accuracy 0.5294612794612794\n",
      "Epoch 12: Training Loss 0.03694941959883037, Validation Loss 1.3590591983389944, Validation Accuracy 0.4823232323232323\n",
      "Epoch 13: Training Loss 0.036451752286208304, Validation Loss 1.262348279497925, Validation Accuracy 0.5345117845117845\n",
      "Epoch 14: Training Loss 0.03547754812240601, Validation Loss 1.2591803524345155, Validation Accuracy 0.5214646464646465\n",
      "Epoch 15: Training Loss 0.03503616985521819, Validation Loss 1.2422515587219163, Validation Accuracy 0.5408249158249159\n",
      "Epoch 16: Training Loss 0.03442236052061382, Validation Loss 1.2549375456393728, Validation Accuracy 0.5340909090909091\n",
      "Epoch 17: Training Loss 0.031920627518704066, Validation Loss 1.194911852960467, Validation Accuracy 0.5660774410774411\n",
      "Epoch 18: Training Loss 0.03259652044898585, Validation Loss 1.2869456738047294, Validation Accuracy 0.5357744107744108\n",
      "Epoch 19: Training Loss 0.03151612158825523, Validation Loss 1.27334149325093, Validation Accuracy 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = 9999\n",
    "count = 0\n",
    "for epoch in tqdm(range(100)):\n",
    "    loss = supervised_classifier.train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = supervised_classifier.test(model, test_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}: Training Loss {loss}, Validation Loss {val_loss}, Validation Accuracy {val_acc}\")\n",
    "    \n",
    "    if best_val_loss < val_loss:\n",
    "        count += 1\n",
    "    else:\n",
    "        best_val_loss = val_loss\n",
    "    if count > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c1880165573a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myhats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_DS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myhats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatterplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "yhats = model(test_DS[:][0]).detach()\n",
    "predictions = yhats.argmax(dim=1)\n",
    "plot = sns.scatterplot(test_y[:,0], test_y[:,1], hue=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a1435b961c93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(test_y[:,0], test_y[:,1], hue=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(predictions, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(predictions, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(predictions, test_labels, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
