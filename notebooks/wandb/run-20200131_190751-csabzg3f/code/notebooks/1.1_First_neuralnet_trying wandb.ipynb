{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/evs/Channel_Charting\" target=\"_blank\">https://app.wandb.ai/evs/Channel_Charting</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/evs/Channel_Charting/runs/vxjke0u0\" target=\"_blank\">https://app.wandb.ai/evs/Channel_Charting/runs/vxjke0u0</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/evs/Channel_Charting/runs/vxjke0u0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"Channel_Charting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_trainer\n",
    "        \n",
    "from ignite.metrics import Accuracy, Loss\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(train_batch_size, val_batch_size):\n",
    "    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    train_loader = DataLoader(MNIST(download=True, root=\".\", transform=data_transform, train=True),\n",
    "                              batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "    val_loader = DataLoader(MNIST(download=False, root=\".\", transform=data_transform, train=False),\n",
    "                            batch_size=val_batch_size, shuffle=False)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def run(train_batch_size, val_batch_size, epochs, lr, momentum, log_interval):\n",
    "    train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n",
    "    model = Net()\n",
    "    device = 'cpu'\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "\n",
    "    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    trainer = create_supervised_trainer(model, optimizer, F.nll_loss, device=device)\n",
    "    evaluator = create_supervised_evaluator(model,\n",
    "                                            metrics={'accuracy': Accuracy(),\n",
    "                                                     'nll': Loss(F.nll_loss)},\n",
    "                                            device=device)\n",
    "\n",
    "    desc = \"ITERATION - loss: {:.2f}\"\n",
    "    pbar = tqdm(\n",
    "        initial=0, leave=False, total=len(train_loader),\n",
    "        desc=desc.format(0)\n",
    "    )\n",
    "\n",
    "    @trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n",
    "    def log_training_loss(engine):\n",
    "        pbar.desc = desc.format(engine.state.output)\n",
    "        pbar.update(log_interval)\n",
    "        wandb.log({\"train loss\": engine.state.output})\n",
    "\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(engine):\n",
    "        pbar.refresh()\n",
    "        evaluator.run(train_loader)\n",
    "        metrics = evaluator.state.metrics\n",
    "        avg_accuracy = metrics['accuracy']\n",
    "        avg_nll = metrics['nll']\n",
    "        tqdm.write(\n",
    "            \"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "            .format(engine.state.epoch, avg_accuracy, avg_nll)\n",
    "        )\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation_results(engine):\n",
    "        evaluator.run(val_loader)\n",
    "        metrics = evaluator.state.metrics\n",
    "        avg_accuracy = metrics['accuracy']\n",
    "        avg_nll = metrics['nll']\n",
    "        tqdm.write(\n",
    "            \"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "            .format(engine.state.epoch, avg_accuracy, avg_nll))\n",
    "\n",
    "        pbar.n = pbar.last_print_n = 0\n",
    "        wandb.log({\"validation loss\": engine.state.metrics['nll']})\n",
    "        wandb.log({\"validation accuracy\": engine.state.metrics['accuracy']})\n",
    "\n",
    "\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=epochs)\n",
    "    pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "\n",
    "hyperparameter_defaults = dict(\n",
    "    batch_size = 256,\n",
    "    val_batch_size = 100,\n",
    "    epochs = 10,\n",
    "    lr = 0.001,\n",
    "    momentum = 0.3,\n",
    "    log_interval = 10,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
