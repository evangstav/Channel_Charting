{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using version \u001b[1m^0.5.0\u001b[0m for \u001b[36mtorchvision\u001b[0m\n",
      "\n",
      "\u001b[34mUpdating dependencies\u001b[0m\n",
      "\u001b[2K\u001b[34mResolving dependencies...\u001b[0m \u001b[30;1m(68.5s)\u001b[0m[34mResolving dependencies...\u001b[0m \u001b[30;1m(4.9s)\u001b[0m\u001b[34mResolving dependencies...\u001b[0m \u001b[30;1m(7.8s)\u001b[0m\u001b[34mResolving dependencies...\u001b[0m \u001b[30;1m(9.4s)\u001b[0m\u001b[34mResolving dependencies...\u001b[0m \u001b[30;1m(14.4s)\u001b[0m\u001b[34mResolving dependencies...\u001b[0m \u001b[30;1m(34.9s)\u001b[0m\u001b[34mResolving dependencies...\u001b[0m \u001b[30;1m(46.3s)\u001b[0m\u001b[34mResolving dependencies...\u001b[0m \u001b[30;1m(57.4s)\u001b[0m\n",
      "\n",
      "\u001b[34mWriting lock file\u001b[0m\n",
      "\n",
      "\n",
      "Package operations: \u001b[34m2\u001b[0m installs, \u001b[34m0\u001b[0m updates, \u001b[34m0\u001b[0m removals\n",
      "\n",
      "  - Installing \u001b[36mpillow\u001b[0m (\u001b[1m7.0.0\u001b[0m)\n",
      "  - Installing \u001b[36mtorchvision\u001b[0m (\u001b[1m0.5.0\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"Channel_Cha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch\n",
    "from torch import nn\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "from ignite.engine import Events, \n",
    "                          create_supervised_trainer,\n",
    "                          create_supervised_trainer\n",
    "        \n",
    "from ignite.metrics import Accuracy, Loss\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-7d51f6e434e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(train_batch_size, val_batch_size):\n",
    "    data_transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    train_loader = DataLoader(MNIST(download=True, root=\".\", transform=data_transform, train=True),\n",
    "                              batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "    val_loader = DataLoader(MNIST(download=False, root=\".\", transform=data_transform, train=False),\n",
    "                            batch_size=val_batch_size, shuffle=False)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def run(train_batch_size, val_batch_size, epochs, lr, momentum, log_interval):\n",
    "    train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n",
    "    model = Net()\n",
    "    device = 'cpu'\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "\n",
    "    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    trainer = create_supervised_trainer(model, optimizer, F.nll_loss, device=device)\n",
    "    evaluator = create_supervised_evaluator(model,\n",
    "                                            metrics={'accuracy': Accuracy(),\n",
    "                                                     'nll': Loss(F.nll_loss)},\n",
    "                                            device=device)\n",
    "\n",
    "    desc = \"ITERATION - loss: {:.2f}\"\n",
    "    pbar = tqdm(\n",
    "        initial=0, leave=False, total=len(train_loader),\n",
    "        desc=desc.format(0)\n",
    "    )\n",
    "\n",
    "    @trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n",
    "    def log_training_loss(engine):\n",
    "        pbar.desc = desc.format(engine.state.output)\n",
    "        pbar.update(log_interval)\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(engine):\n",
    "        pbar.refresh()\n",
    "        evaluator.run(train_loader)\n",
    "        metrics = evaluator.state.metrics\n",
    "        avg_accuracy = metrics['accuracy']\n",
    "        avg_nll = metrics['nll']\n",
    "        tqdm.write(\n",
    "            \"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "            .format(engine.state.epoch, avg_accuracy, avg_nll)\n",
    "        )\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation_results(engine):\n",
    "        evaluator.run(val_loader)\n",
    "        metrics = evaluator.state.metrics\n",
    "        avg_accuracy = metrics['accuracy']\n",
    "        avg_nll = metrics['nll']\n",
    "        tqdm.write(\n",
    "            \"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "            .format(engine.state.epoch, avg_accuracy, avg_nll))\n",
    "\n",
    "        pbar.n = pbar.last_print_n = 0\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=epochs)\n",
    "    pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
